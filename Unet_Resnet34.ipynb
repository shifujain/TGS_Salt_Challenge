{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport six\n\nfrom random import randint\n\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.transform import resize\n\nfrom keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.preprocessing.image import load_img\nfrom keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\nfrom keras.layers import Conv2D, Concatenate, MaxPooling2D\nfrom keras.layers import UpSampling2D, Dropout, BatchNormalization\nfrom tqdm import tqdm_notebook\nfrom keras import initializers\nfrom keras import regularizers\nfrom keras import constraints\nfrom keras.utils import conv_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.engine.topology import get_source_inputs\nfrom keras.engine import InputSpec\nfrom keras import backend as K\n#from keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.regularizers import l2\nfrom keras import optimizers\n\n\nfrom keras.engine.topology import Input\nfrom keras.engine.training import Model\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.core import Activation, SpatialDropout2D\nfrom keras.layers.merge import concatenate,add\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.pooling import MaxPooling2D\n\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.model_selection import KFold\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "08a245fdea3f5855aeb74165002c632b1d1dd172"
      },
      "cell_type": "code",
      "source": "import time\nt_start = time.time()\nversion = 13\nbasic_name = f'Unet_resnet_version_{version}'\nsave_model_name = basic_name + '.model'\nsubmission_file = basic_name + '.csv'\n\nprint(save_model_name)\nprint(submission_file)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "710ea46013825e25df357d23173b226c15577298"
      },
      "cell_type": "code",
      "source": "img_size_ori = 101\nimg_size_target = 101\n\nepochs = 75\nbatch_size = 32\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n    #res[:img_size_ori, :img_size_ori] = img\n    #return res\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n    #return img[:img_size_ori, :img_size_ori]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c61a97a8f5bc2920d34ab403ab6db56d35074765"
      },
      "cell_type": "code",
      "source": "train_df = pd.read_csv(\"../input/tgs-salt-identification-challenge/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/tgs-salt-identification-challenge/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16141176600c0d7ddef3d31b3ab90ca52ee3d42f"
      },
      "cell_type": "code",
      "source": "train_df[\"images\"] = [np.array(load_img(\"../input/tgs-salt-identification-challenge/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05ff9d18198b17d3080b788c14953e1bc33f5c41"
      },
      "cell_type": "code",
      "source": "train_df[\"masks\"] = [np.array(load_img(\"../input/tgs-salt-identification-challenge/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "51d4bf4b9981bc4f676711f39dd550718005eb38"
      },
      "cell_type": "code",
      "source": "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8dece6c92829f8d09874ad6966f778ba88a3b696"
      },
      "cell_type": "code",
      "source": "def cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eef50f94e1bd5179c900c20240ee2f2bd65b71d2"
      },
      "cell_type": "code",
      "source": "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.map(upsample).tolist()).reshape(-1,img_size_target, img_size_target, 1), \n    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size = 0.05 , stratify=train_df.coverage_class, random_state=42)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "821a7f4d986b9a3fbe76dd207743e8fad61f7cda"
      },
      "cell_type": "code",
      "source": "def BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = BatchActivate(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate:\n        x = BatchActivate(x)\n    return x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f097172c0b0566e1bb66334a8828c0b4e5c3fa3"
      },
      "cell_type": "code",
      "source": "size = (3, 3)\ndef build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, size, activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1, True)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, size, activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2, True)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, size, activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4, True)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, size, activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8, True)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, size, activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16, True)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, size, strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n    \n    # 12 -> 25\n    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3 = Conv2DTranspose(start_neurons * 4, size, strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, size, strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n    \n    # 50 -> 101\n    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    deconv1 = Conv2DTranspose(start_neurons * 1, size, strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n    \n    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n    output_layer =  Activation('sigmoid')(output_layer_noActi)\n    \n    return output_layer",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcfb90497c58ff56cb49b67352b1319301f15557"
      },
      "cell_type": "code",
      "source": "def get_iou_vector(A, B):\n    batch_size = A.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        t, p = A[batch]>0, B[batch]>0\n#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n#             metric.append(0)\n#             continue\n#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n#             metric.append(0)\n#             continue\n#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n#             metric.append(1)\n#             continue\n        \n        intersection = np.logical_and(t, p)\n        union = np.logical_or(t, p)\n        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n        thresholds = np.arange(0.5, 1, 0.05)\n        s = []\n        for thresh in thresholds:\n            s.append(iou > thresh)\n        metric.append(np.mean(s))\n\n    return np.mean(metric)\n\ndef my_iou_metric(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0.3], tf.float64)#change 0.5 >> 0.7\n\ndef my_iou_metric_2(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0.1], tf.float64)#change 0.0 >> 0.5\n\ndef my_iou_metric_3(label, pred):\n    return tf.py_func(get_iou_vector, [label, pred > 0.3], tf.float64)#change 0.0 >> 0.5",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e64fa9fe0763f552f14460f651f967993a502e63"
      },
      "cell_type": "code",
      "source": "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    gts = tf.reduce_sum(gt_sorted)\n    intersection = gts - tf.cumsum(gt_sorted)\n    union = gts + tf.cumsum(1. - gt_sorted)\n    jaccard = 1. - intersection / union\n    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n    return jaccard\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        def treat_image(log_lab):\n            log, lab = log_lab\n            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n            log, lab = flatten_binary_scores(log, lab, ignore)\n            return lovasz_hinge_flat(log, lab)\n        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n        loss = tf.reduce_mean(losses)\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n\n    def compute_loss():\n        labelsf = tf.cast(labels, logits.dtype)\n        signs = 2. * labelsf - 1.\n        errors = 1. - logits * tf.stop_gradient(signs)\n        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n        gt_sorted = tf.gather(labelsf, perm)\n        grad = lovasz_grad(gt_sorted)\n        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n        return loss\n\n    # deal with the void prediction case (only void pixels)\n    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n                   lambda: tf.reduce_sum(logits) * 0.,\n                   compute_loss,\n                   strict=True,\n                   name=\"loss\"\n                   )\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = tf.reshape(scores, (-1,))\n    labels = tf.reshape(labels, (-1,))\n    if ignore is None:\n        return scores, labels\n    valid = tf.not_equal(labels, ignore)\n    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n    return vscores, vlabels\n\ndef lovasz_loss(y_true, y_pred):\n    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n    #logits = K.log(y_pred / (1. - y_pred))\n    logits = y_pred #Jiaxin\n    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n    return loss",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a2524e9cbcda5007afedba276cbcaba0984bd29"
      },
      "cell_type": "code",
      "source": "# https://github.com/raghakot/keras-resnet/blob/master/resnet.py\ndef _bn_relu(input):\n    \"\"\"Helper to build a BN -> relu block\n    \"\"\"\n    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n    return Activation(\"relu\")(norm)\n\n\ndef _conv_bn_relu(**conv_params):\n    \"\"\"Helper to build a conv -> BN -> relu block\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=kernel_regularizer)(input)\n        return _bn_relu(conv)\n\n    return f\n\n\ndef _bn_relu_conv(**conv_params):\n    \"\"\"Helper to build a BN -> relu -> conv block.\n    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n    \"\"\"\n    filters = conv_params[\"filters\"]\n    kernel_size = conv_params[\"kernel_size\"]\n    strides = conv_params.setdefault(\"strides\", (1, 1))\n    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n    padding = conv_params.setdefault(\"padding\", \"same\")\n    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n\n    def f(input):\n        activation = _bn_relu(input)\n        return Conv2D(filters=filters, kernel_size=kernel_size,\n                      strides=strides, padding=padding,\n                      kernel_initializer=kernel_initializer,\n                      kernel_regularizer=kernel_regularizer)(activation)\n\n    return f\n\n\ndef _shortcut(input, residual):\n    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n    \"\"\"\n    # Expand channels of shortcut to match residual.\n    # Stride appropriately to match residual (width, height)\n    # Should be int if network architecture is correctly configured.\n    input_shape = K.int_shape(input)\n    residual_shape = K.int_shape(residual)\n    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n\n    shortcut = input\n    # 1 X 1 conv if shape is different. Else identity.\n    if stride_width > 1 or stride_height > 1 or not equal_channels:\n        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n                          kernel_size=(1, 1),\n                          strides=(stride_width, stride_height),\n                          padding=\"valid\",\n                          kernel_initializer=\"he_normal\",\n                          kernel_regularizer=l2(0.0001))(input)\n\n    return add([shortcut, residual])\n\ndef basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n    \"\"\"\n    def f(input):\n\n        if is_first_block_of_first_layer:\n            # don't repeat bn->relu since we just did bn->relu->maxpool\n            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n                           strides=init_strides,\n                           padding=\"same\",\n                           kernel_initializer=\"he_normal\",\n                           kernel_regularizer=l2(1e-4))(input)\n        else:\n            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n                                  strides=init_strides)(input)\n\n        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n        return _shortcut(input, residual)\n\n    return f\n\ndef _residual_block(block_function, filters, repetitions, is_first_layer=False):\n    \"\"\"Builds a residual block with repeating bottleneck blocks.\n    \"\"\"\n    def f(input):\n        for i in range(repetitions):\n            init_strides = (1, 1)\n            if i == 0 and not is_first_layer:\n                init_strides = (2, 2)\n            input = block_function(filters=filters, init_strides=init_strides,\n                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n        return input\n\n    return f\n\ndef _handle_dim_ordering():\n    global ROW_AXIS\n    global COL_AXIS\n    global CHANNEL_AXIS\n    if K.image_dim_ordering() == 'tf':\n        ROW_AXIS = 1\n        COL_AXIS = 2\n        CHANNEL_AXIS = 3\n    else:\n        CHANNEL_AXIS = 1\n        ROW_AXIS = 2\n        COL_AXIS = 3\n\n\ndef _get_block(identifier):\n    if isinstance(identifier, six.string_types):\n        res = globals().get(identifier)\n        if not res:\n            raise ValueError('Invalid {}'.format(identifier))\n        return res\n    return identifier\n\n\nclass ResnetBuilder(object):\n    @staticmethod\n    def build(input_shape, block_fn, repetitions,input_tensor):\n        _handle_dim_ordering()\n        if len(input_shape) != 3:\n            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n\n        # Permute dimension order if necessary\n        if K.image_dim_ordering() == 'tf':\n            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n\n        # Load function from str if needed.\n        block_fn = _get_block(block_fn)\n        \n        if input_tensor is None:\n            img_input = Input(shape=input_shape)\n        else:\n            if not K.is_keras_tensor(input_tensor):\n                img_input = Input(tensor=input_tensor, shape=input_shape)\n            else:\n                img_input = input_tensor\n                \n        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(img_input)\n        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n\n        block = pool1\n        filters = 64\n        for i, r in enumerate(repetitions):\n            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n            filters *= 2\n\n        # Last activation\n        block = _bn_relu(block)\n\n        model = Model(inputs=img_input, outputs=block)\n        return model\n\n    @staticmethod\n    def build_resnet_34(input_shape,input_tensor):\n        return ResnetBuilder.build(input_shape, basic_block, [3, 4, 6, 3],input_tensor)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4de1ee88a15a7b355fcafc91cc6e060fd0c164e1"
      },
      "cell_type": "code",
      "source": "def UResNet34(input_shape=(128, 128, 1), classes=1, decoder_filters=16, decoder_block_type='upsampling',\n                       encoder_weights=\"imagenet\", input_tensor=None, activation='sigmoid', **kwargs):\n\n    backbone = ResnetBuilder.build_resnet_34(input_shape=input_shape,input_tensor=input_tensor)\n    \n    input_layer = backbone.input #input = backbone.input\n    output_layer = build_model(input_layer, 16,0.5) #x\n    model = Model(input_layer, output_layer)\n    c = optimizers.adam(lr = 0.03)\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n    model.name = 'u-resnet34'\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ad9d39e1976d08914b65fbacb60c10ea947ac9c"
      },
      "cell_type": "code",
      "source": "model1 = UResNet34( input_shape = (1,img_size_target,img_size_target))\n# model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4e763ee922ffa0e6386b8b9eee4b04d93f5f7547"
      },
      "cell_type": "markdown",
      "source": "Apply augmentations like fliping the image left to right."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b93c7c9e392ce8f3643ea7b527399d7715a32fa6"
      },
      "cell_type": "code",
      "source": "#augmentation\nx_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f70c0c3eed61a7ae1194e92c2f56b6fbaef37448"
      },
      "cell_type": "code",
      "source": "# #early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n# model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n#                                    mode = 'max', save_best_only=True, verbose=1)\n# reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n\n# history = model1.fit(x_train, y_train,\n#                     validation_data=[x_valid, y_valid], \n#                     epochs=epochs,\n#                     batch_size=batch_size,\n#                     callbacks=[ model_checkpoint,reduce_lr], \n#                     verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1397facdfddda9951dd3f45925178a2cd38eda96"
      },
      "cell_type": "code",
      "source": "# model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n# # remove layter activation layer and use losvasz loss\n# input_x = model1.layers[0].input\n\n# output_layer = model1.layers[-1].input\n# model = Model(input_x, output_layer)\n# c = optimizers.adam(lr = 0.01)\n\n# # lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n# # Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n# model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b5a350bb4c95b909672031ac3aabac349e256110"
      },
      "cell_type": "markdown",
      "source": "Use pretrained model(trained in previous iterations) to further train the model with Lovasz_loss."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "289de7378ae11a0d067dc82837e1743e959068df"
      },
      "cell_type": "code",
      "source": "model = load_model('../input/saved-models/Unet_resnet_version_11.model',custom_objects={'my_iou_metric_2': my_iou_metric_2,\n                                                   'lovasz_loss': lovasz_loss})\n# early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=30, verbose=1)\nmodel_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n                                   mode = 'max', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\nepochs = 75\nbatch_size = 32\n\nhistory = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[model_checkpoint,reduce_lr],#,early_stopping], \n                    verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c892458ae320710b29cf8f077d4f13f7fca8d49e"
      },
      "cell_type": "code",
      "source": "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n                                                   'lovasz_loss': lovasz_loss})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a7181295df07098f17027efa3b90ec664fc087d"
      },
      "cell_type": "code",
      "source": "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n    return preds_test/2",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fff3a6998274541777b375dfb8ad125aaf1e3997"
      },
      "cell_type": "code",
      "source": "preds_valid = predict_result(model,x_valid,img_size_target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad74eb7de5180900d3e9c7274761d431eb9c3f54"
      },
      "cell_type": "code",
      "source": "#Score the model and do a threshold optimization by the best IoU.\n# src: https://www.kaggle.com/aglotero/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n\n\n    true_objects = 2\n    pred_objects = 2\n\n    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n    #print(temp1)\n    intersection = temp1[0]\n    #print(\"temp2 = \",temp1[1])\n    #print(intersection.shape)\n   # print(intersection)\n    # Compute areas (needed for finding the union between all objects)\n    #print(np.histogram(labels, bins = true_objects))\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    #print(\"area_true = \",area_true)\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n  \n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2d374b316adbb0e3aba456e71e4e2c04569c41b"
      },
      "cell_type": "code",
      "source": "## Scoring for last model, choose threshold by validation data \nthresholds_ori = np.linspace(0.3, 0.7, 31)\n# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\nthresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n\n# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n# print(ious)\nious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\nprint(ious)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07f2e23e920787118510ebaa56aa1e681eceea05"
      },
      "cell_type": "code",
      "source": "# instead of using default 0 as threshold, use validation data to find the best threshold.\nthreshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ea8651a5c48eac6634b6419707e5845b33a9cee"
      },
      "cell_type": "code",
      "source": "\"\"\"\nused for converting the decoded image to rle mask\nFast compared to previous one\n\"\"\"\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "211d295c28a633263698a6df3128b7fa3da3439a"
      },
      "cell_type": "code",
      "source": "x_test = np.array([(np.array(load_img(\"../input/tgs-salt-identification-challenge/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2d8b064842e8ace0a553aeb1781e184f0cef2671"
      },
      "cell_type": "code",
      "source": "preds_test = predict_result(model,x_test,img_size_target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d9634029024f6030df844c2c30e215089bcf228"
      },
      "cell_type": "code",
      "source": "t1 = time.time()\npred_dict = {idx: rle_encode(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\nt2 = time.time()\n\nprint(f\"Usedtime = {t2-t1} s\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c0d45476e89b6d66ced993c8c9e307be140b1b9"
      },
      "cell_type": "code",
      "source": "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv(submission_file)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0ac6363e75f22b699754d52c6b5353a08c06849f"
      },
      "cell_type": "code",
      "source": "t_finish = time.time()\nprint(f\"Kernel run time = {(t_finish-t_start)/3600} hours\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5caf4d7109f0cdc54807d899fa4fc336e70a87f"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f6ffde6ff6f15013b384fb376791d03de7784f67"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}